{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import cv2  # OpenCV for computer vision tasks\n",
        "import tkinter as tk  # Tkinter for GUI\n",
        "from tkinter import messagebox, Menu  # Messagebox for error handling and Menu for adding menu bar\n",
        "from threading import Thread  # Threading for running tasks in parallel\n",
        "from PIL import Image, ImageTk  # PIL for image processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def faceBox(faceNet, frame):\n",
        "    frameHeight = frame.shape[0]\n",
        "    frameWidth = frame.shape[1]\n",
        "    \n",
        "    # Create a blob from the frame to pass it through the network\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), [104, 117, 123], swapRB=False)\n",
        "    faceNet.setInput(blob)\n",
        "    \n",
        "    # Perform forward pass to get the face detections\n",
        "    detections = faceNet.forward()\n",
        "    bboxs = []\n",
        "    \n",
        "    # Iterate over all detections\n",
        "    for i in range(detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        \n",
        "        # Filter out weak detections by ensuring the confidence is greater than a threshold\n",
        "        if confidence > 0.7:\n",
        "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
        "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
        "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
        "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
        "            \n",
        "            # Append the bounding box coordinates to the list\n",
        "            bboxs.append([x1, y1, x2, y2])\n",
        "            \n",
        "            # Draw the bounding box on the frame\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    \n",
        "    return frame, bboxs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model configuration and weights files for face, age, and gender detection\n",
        "faceProto = \"opencv_face_detector.pbtxt\"  # Path to the face detector configuration file\n",
        "faceModel = \"opencv_face_detector_uint8.pb\"  # Path to the face detector weights file\n",
        "ageProto = \"age_deploy.prototxt\"  # Path to the age detector configuration file\n",
        "ageModel = \"age_net.caffemodel\"  # Path to the age detector weights file\n",
        "genderProto = \"gender_deploy.prototxt\"  # Path to the gender detector configuration file\n",
        "genderModel = \"gender_net.caffemodel\"  # Path to the gender detector weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    faceNet = cv2.dnn.readNet(faceModel, faceProto)\n",
        "    ageNet = cv2.dnn.readNet(ageModel, ageProto)\n",
        "    genderNet = cv2.dnn.readNet(genderModel, genderProto)\n",
        "    print(\"Models loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading models: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
        "ageList = ['(0-2)', '3-5', '6-8', '9-12', '13-17', '18-22', '23-27', '28-32', '33-37', '38-42', '43-47', '48-52', '53-57', '58-62']\n",
        "genderList = ['Male', 'Female']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def start_camera():\n",
        "    video = cv2.VideoCapture(0)\n",
        "    video.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)  # Set width to 1280 for 720p\n",
        "    video.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)  # Set height to 720 for 720p\n",
        "    if not video.isOpened():\n",
        "        messagebox.showerror(\"Error\", \"Failed to open camera!\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            messagebox.showerror(\"Error\", \"Failed to read frame from camera!\")\n",
        "            break\n",
        "\n",
        "        frame = cv2.flip(frame, 1)  # Fix the camera inverse mirroring\n",
        "\n",
        "        # Detect faces\n",
        "        frame, bboxs = faceBox(faceNet, frame)\n",
        "\n",
        "        for bbox in bboxs:\n",
        "            face = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
        "            blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
        "            \n",
        "            # Predict gender\n",
        "            genderNet.setInput(blob)\n",
        "            genderPred = genderNet.forward()\n",
        "            gender = genderList[genderPred[0].argmax()]\n",
        "\n",
        "            # Predict age\n",
        "            ageNet.setInput(blob)\n",
        "            agePred = ageNet.forward()\n",
        "            age = ageList[agePred[0].argmax()]\n",
        "\n",
        "            label = \"{},{}\".format(gender, age)\n",
        "            cv2.putText(frame, label, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "        # Convert the frame to RGB format\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame = Image.fromarray(frame)  # Convert OpenCV array to PIL Image\n",
        "\n",
        "        # Maintain aspect ratio\n",
        "        frame_width, frame_height = frame.size\n",
        "        aspect_ratio = frame_width / frame_height\n",
        "        new_width = 720\n",
        "        new_height = int(new_width / aspect_ratio)\n",
        "        frame = frame.resize((new_width, new_height))\n",
        "\n",
        "        # Convert PIL Image to ImageTk format\n",
        "        img = ImageTk.PhotoImage(image=frame)\n",
        "\n",
        "        # Schedule the image update in the main thread using root.after\n",
        "        root.after(0, update_image, img)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_image(img):\n",
        "    panel.config(image=img)\n",
        "    panel.image = img  # Ensure the image remains referenced\n",
        "\n",
        "# Function to handle the button press\n",
        "def open_camera():\n",
        "    # Run the camera in a separate thread\n",
        "    global camera_thread\n",
        "    camera_thread = Thread(target=start_camera)\n",
        "    camera_thread.daemon = True  # Ensure the thread exits when the main program does\n",
        "    camera_thread.start()\n",
        "\n",
        "# Function to close the application\n",
        "def exit_app():\n",
        "    root.quit()  # Close the Tkinter application\n",
        "    root.destroy()  # Destroy the Tkinter window\n",
        "\n",
        "# Create the Tkinter window\n",
        "root = tk.Tk()\n",
        "root.title(\"Face Age & Gender Detection\")\n",
        "\n",
        "# Create a menu bar\n",
        "menu_bar = Menu(root)\n",
        "root.config(menu=menu_bar)\n",
        "\n",
        "# Add a menu\n",
        "file_menu = Menu(menu_bar, tearoff=0)\n",
        "menu_bar.add_cascade(label=\"File\", menu=file_menu)\n",
        "file_menu.add_command(label=\"Open Camera\", command=open_camera)\n",
        "file_menu.add_separator()\n",
        "file_menu.add_command(label=\"Exit\", command=exit_app)\n",
        "\n",
        "# Create a button to open the camera\n",
        "open_button = tk.Button(root, text=\"Open Camera\", width=20, height=2, command=open_camera)\n",
        "open_button.pack(pady=10)\n",
        "\n",
        "# Create a button to exit the application\n",
        "exit_button = tk.Button(root, text=\"Exit\", width=20, height=2, command=exit_app)\n",
        "exit_button.pack(pady=10)\n",
        "\n",
        "# Panel to display the video\n",
        "panel = tk.Label(root)\n",
        "panel.pack()\n",
        "\n",
        "root.mainloop()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
